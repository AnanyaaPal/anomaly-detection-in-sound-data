![TU Dortmund Logo](assets/TU_Dortmund_logo.png)
# Interpretable Anomaly Detection in Sound Data

A variety of industrial applications require explainable anomaly detection algorithms. This project focuses on conducting a comprehensive comparison of the already established algorithms from a variety of domains in the field (Deep Learning ~ Autoencoder, Quantile-Quantile Differences ~ Statistical Algo ~ Sound Spectogram) and the latest algorithm, namely, an Isolation Forest (~Supervised Learning). 

## Goal of the project
To provide practical recommendations for interpretable anomaly detection, based on systematic benchmarking.

## Dataset

## Project Installation
Step 1 - Clone the git repository.

Step 2- Install project dependencies as follows:
```
pip install -r requirements.txt
```

## Progress
| Index | Description | Progress
| --- | --- | ---
| 1 | Case A: Implementation of Methods without bootstrapping | [Completed](experiments/without%20bootstrapping)
| 2 | Case B: Implementation of Methods with bootstrapping | [Completed](experiments/with%20bootstrapping)
| 3 | Case A: Comparison of Metrics | [Completed](experiments/without%20bootstrapping/compare_methods.ipynb)
| 4 | Case B: Comparison of Metrics | In Progress

## Interim Presentation of Results 
To be updated
 